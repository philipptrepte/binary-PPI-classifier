% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ppi_prediction.R
\name{ppi.prediction}
\alias{ppi.prediction}
\title{Function to use a support vector or random forest machine learning algorithm or to classify quantitative protein-protein interaction data.}
\usage{
ppi.prediction(
  PPIdf = NULL,
  referenceSet = NULL,
  seed = 555,
  method.scaling = "robust.scaler",
  iter.scaler = TRUE,
  range = c(0.25, 0.75),
  data.scaling = "main",
  negative.reference = c("RRS", "inter-complex"),
  assay = c("mean_cBRET", "mean_mCit"),
  all.configurations = TRUE,
  sampling = NULL,
  weightBy = "mean_cBRET",
  weightHi = TRUE,
  model.type = "svm",
  kernelType = "linear",
  svm.parameters = FALSE,
  C = 100,
  gamma = NULL,
  coef0 = 0,
  degree = 2,
  ensembleSize = 50,
  top = NULL,
  inclusion = NULL,
  cs = "median",
  iter = 5,
  verbose = TRUE
)
}
\arguments{
\item{PPIdf:}{binary PPI data set containing interactions to be classified}

\item{referenceSet:}{reference PPI data set containing reference interactions used to train the svm models}

\item{seed:}{set seed}

\item{method.scaling:}{accepted scaling arguments are: "none", "standardize", "robust.scaler", "construct", "orientation"}

\item{iter.scaler:}{if TRUE and when using "robust.scaler" it iteratively performs robust scaler normalization until the IQR of each construct is within the IQR of all loaded data sets}

\item{range:}{IQR range used in "robust.scaler"}

\item{data.scaling:}{speficies which data provided under 'assay' is scaled. When "main" only the first assay is scaled. When "all", all the assays are scaled.}

\item{negative.reference:}{string in the column "complex" to specify the negative/random interactions}

\item{assay:}{assay parameters used for training}

\item{all.configurations:}{if TRUE all orientations for each interactions are used; if FALSE only the highest scoring orientation for each interaction is used}

\item{sampling:}{if TRUE weighted sampling is used when assembling the positive training sets}

\item{weightBy:}{assay parameter used for weighted sampling}

\item{weightHi:}{if TRUE weighted sampling uses preferentially higher values; if FALSE weighted sampling uses preferentially smaller values}

\item{model.type:}{the machine learning algorithm used. Support are support vector machines: "svm" and random fores: "randomForest}

\item{kernelType:}{the kernel used in training and predicting, see ?e1071::svm for details}

\item{svm.parameters:}{if TRUE, the best parameters (degree, gamma, coef0, cost) are calculated; if FALSE the parameters must be provided manually}

\item{C:}{cost of constraints violation (default: 1)—it is the ‘C’-constant of the regularization term in the Lagrange formulation; see ?e1071::svm for details}

\item{gamma:}{parameter needed for all kernels except linear (default: 1/(data dimension)); see ?e1071::svm for details}

\item{coef0:}{parameter needed for kernels of type polynomial and sigmoid (default: 0); see ?e1071::svm for details}

\item{degree:}{parameter needed for kernel of type polynomial (default: 3); see ?e1071::svm for details}

\item{ensembleSize:}{number of independent training sets assembled}

\item{top:}{number of highest scoring prs and rrs interactions to randomly sample from; if NULL, only interactions above the 'cs' will be used}

\item{inclusion:}{number of interactions to include during training of each model (>30); if NULL, number of interactions are calculated from the training sets assembled (ensembleSize) so that each interaction has been sampled with a 99.99\% probability.}

\item{cs:}{sample interactions with quantitative scores above the specified 'cs' from the main assay}

\item{iter:}{number of iterations performed to reclassify the training set}

\item{verbose:}{give detailed information}
}
\value{
A list containing the results from the machine learning prediction classes and the parameters used. Input for the learning.curve function.
}
\description{
Function to use a support vector or random forest machine learning algorithm or to classify quantitative protein-protein interaction data.
}
\examples{
load('data/luthy_reference_sets.RData')
example <- ppi.prediction(PPIdf = luthy_reference_sets, referenceSet = luthy_reference_sets,
                          assay = c("mean_cBRET", "mean_mCit"), negative.reference = c("RRS"),
                          model.type = "svm", ensembleSize = 50,
                          sampling = 'weighted', weightBy = "mean_cBRET")

}
